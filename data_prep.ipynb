{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "This notebook contains the code for data loading, preparation and chunking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_squad = squad[\"train\"]\n",
    "val_squad = squad[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_squad.to_pandas()\n",
    "val_df = val_squad.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>{'text': ['a copper statue of Christ'], 'answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>{'text': ['the Main Building'], 'answer_start'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>{'text': ['a Marian place of prayer and reflec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>{'text': ['a golden statue of the Virgin Mary'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                     title  \\\n",
       "0  5733be284776f41900661182  University_of_Notre_Dame   \n",
       "1  5733be284776f4190066117f  University_of_Notre_Dame   \n",
       "2  5733be284776f41900661180  University_of_Notre_Dame   \n",
       "3  5733be284776f41900661181  University_of_Notre_Dame   \n",
       "4  5733be284776f4190066117e  University_of_Notre_Dame   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                             answers  \n",
       "0  {'text': ['Saint Bernadette Soubirous'], 'answ...  \n",
       "1  {'text': ['a copper statue of Christ'], 'answe...  \n",
       "2  {'text': ['the Main Building'], 'answer_start'...  \n",
       "3  {'text': ['a Marian place of prayer and reflec...  \n",
       "4  {'text': ['a golden statue of the Virgin Mary'...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['context_id'] = train_df['context'].astype('category').cat.codes\n",
    "context_df = train_df[['context_id', 'context', 'title']].drop_duplicates().reset_index(drop=True)\n",
    "queries_df = train_df[['context_id', 'question', 'answers']]\n",
    "queries_df['answer_text'] = queries_df['answers'].apply(lambda x: x['text'][0] if x['text'] else '')\n",
    "queries_df['answer_start'] = queries_df['answers'].apply(lambda x: x['answer_start'][0] if x['answer_start'] else -1)\n",
    "del queries_df['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['context_id'] = val_df['context'].astype('category').cat.codes\n",
    "context_df_val = val_df[['context_id', 'context', 'title']].drop_duplicates().reset_index(drop=True)\n",
    "queries_df_val = val_df[['context_id', 'question', 'answers']]\n",
    "queries_df_val['answer_text'] = queries_df_val['answers'].apply(\n",
    "    lambda x: x['text'][0] if isinstance(x['text'], (list, np.ndarray)) and len(x['text']) > 0 else ''\n",
    ")\n",
    "queries_df_val['answer_start'] = queries_df_val['answers'].apply(\n",
    "    lambda x: x['answer_start'][0] if isinstance(x['answer_start'], (list, np.ndarray)) and len(x['answer_start']) > 0 else -1\n",
    ")\n",
    "del queries_df_val['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Coreference Resolution Stub ----------\n",
    "def apply_coreference(text):\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Sentence Cleaning ----------\n",
    "def clean_text(text: str) -> str:\n",
    "    # Remove unwanted characters\n",
    "    text = re.sub(r\"[^a-zA-Z0-9.,;!?\\'\\\"()\\/\\-\\:$% ]+\", \" \", text)\n",
    "    # Collapse multiple spaces/newlines/tabs into one\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Sliding Window Chunking ----------\n",
    "def sliding_window_chunks(text, chunk_size=300, stride=100):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        chunks.append((text[start:end], start, end))\n",
    "        if end == len(text):\n",
    "            break\n",
    "        start += stride\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Semantic Chunking ----------\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def semantic_chunks(text, sim_threshold=0.6, max_chunk_size=500):\n",
    "    sentences = sent_tokenize(text)\n",
    "    # compute char offsets robustly\n",
    "    offsets = []\n",
    "    pos = 0\n",
    "    for s in sentences:\n",
    "        start = text.find(s, pos)\n",
    "        if start == -1:\n",
    "            start = pos\n",
    "        end = start + len(s)\n",
    "        offsets.append((s, start, end))\n",
    "        pos = end\n",
    "\n",
    "    if not offsets:\n",
    "        return []\n",
    "\n",
    "    sents = [s for (s, _, _) in offsets]\n",
    "    emb = model.encode(sents, convert_to_tensor=True)\n",
    "    chunks = []\n",
    "    cur_sents = [offsets[0]]\n",
    "    prev_emb = emb[0]\n",
    "\n",
    "    for i in range(1, len(offsets)):\n",
    "        sent, st, ed = offsets[i]\n",
    "        cur_emb = emb[i]\n",
    "        sim = util.cos_sim(prev_emb, cur_emb).item()\n",
    "        cur_text_len = offsets[i][2] - offsets[i - len(cur_sents)][1]\n",
    "\n",
    "        if sim >= sim_threshold and cur_text_len <= max_chunk_size:\n",
    "            cur_sents.append(offsets[i])\n",
    "        else:\n",
    "            start_char = cur_sents[0][1]\n",
    "            end_char = cur_sents[-1][2]\n",
    "            chunk_text = text[start_char:end_char]\n",
    "            chunks.append((chunk_text, start_char, end_char))\n",
    "            cur_sents = [offsets[i]]\n",
    "        prev_emb = cur_emb\n",
    "\n",
    "    if cur_sents:\n",
    "        start_char = cur_sents[0][1]\n",
    "        end_char = cur_sents[-1][2]\n",
    "        chunks.append((text[start_char:end_char], start_char, end_char))\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Build Chunk DataFrame ----------\n",
    "def build_chunk_df(df, chunk_func, coref=False, **kwargs):\n",
    "    all_chunks = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        orig_context = row[\"context\"]\n",
    "        context = orig_context\n",
    "        if coref:\n",
    "            # For embeddings: resolved text; offsets stay on orig_context\n",
    "            resolved_context = apply_coreference(orig_context)\n",
    "            context_for_offsets = orig_context\n",
    "            context_for_embedding = resolved_context\n",
    "        else:\n",
    "            context_for_offsets = orig_context\n",
    "            context_for_embedding = orig_context\n",
    "\n",
    "        chunks_offsets = chunk_func(context_for_offsets, **kwargs)\n",
    "\n",
    "        for i, (chunk_text, start, end) in enumerate(chunks_offsets):\n",
    "            # chunk text for embedding (coref-resolved if coref=True)\n",
    "            chunk_embed_text = context_for_embedding[start:end]\n",
    "\n",
    "            chunk_text = clean_text(chunk_text)\n",
    "            chunk_embed_text = clean_text(chunk_embed_text)\n",
    "\n",
    "            all_chunks.append({\n",
    "                \"context_id\": row[\"context_id\"],\n",
    "                \"chunk_id\": f\"{row[\"context_id\"]}_{i}\",\n",
    "                \"chunk_text\": chunk_text,\n",
    "                \"chunk_embed_text\": chunk_embed_text,\n",
    "                \"title\": row.get(\"title\", \"\"),\n",
    "                \"chunk_start\": start,\n",
    "                \"chunk_end\": end,\n",
    "                \"coref\": coref,\n",
    "                \"chunking_type\": chunk_func.__name__\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(all_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18891it [00:01, 12999.40it/s]\n",
      "2067it [00:00, 12237.13it/s]\n"
     ]
    }
   ],
   "source": [
    "df_sliding_train = build_chunk_df(context_df, sliding_window_chunks, coref=False, chunk_size=300, stride=200)\n",
    "df_sliding_val = build_chunk_df(context_df_val, sliding_window_chunks, coref=False, chunk_size=300, stride=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18891it [05:43, 55.00it/s]\n",
      "2067it [00:38, 53.05it/s]\n"
     ]
    }
   ],
   "source": [
    "df_semantic_train = build_chunk_df(context_df, semantic_chunks, coref=False, sim_threshold=0.6, max_chunk_size=500)\n",
    "df_semantic_val = build_chunk_df(context_df_val, semantic_chunks, coref=False, sim_threshold=0.6, max_chunk_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sliding_coref = build_chunk_df(train_df, sliding_window_chunks, coref=True, chunk_size=300, stride=100)\n",
    "#df_semantic_coref = build_chunk_df(train_df, semantic_chunks, coref=True, sim_threshold=0.6, max_chunk_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sliding train: (70068, 9)\n",
      "Semantic train: (84007, 9)\n"
     ]
    }
   ],
   "source": [
    "# ---------- Quick Check ----------\n",
    "print(\"Sliding train:\", df_sliding_train.shape)\n",
    "print(\"Semantic train:\", df_semantic_train.shape)\n",
    "#print(\"Sliding+Coref:\", df_sliding_coref.shape)\n",
    "#print(\"Semantic+Coref:\", df_semantic_coref.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk_text</th>\n",
       "      <th>chunk_embed_text</th>\n",
       "      <th>title</th>\n",
       "      <th>chunk_start</th>\n",
       "      <th>chunk_end</th>\n",
       "      <th>coref</th>\n",
       "      <th>chunking_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1683</td>\n",
       "      <td>1683_0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>False</td>\n",
       "      <td>semantic_chunks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1683</td>\n",
       "      <td>1683_1</td>\n",
       "      <td>Atop the Main Building's gold dome is a golden...</td>\n",
       "      <td>Atop the Main Building's gold dome is a golden...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>54</td>\n",
       "      <td>127</td>\n",
       "      <td>False</td>\n",
       "      <td>semantic_chunks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1683</td>\n",
       "      <td>1683_2</td>\n",
       "      <td>Immediately in front of the Main Building and ...</td>\n",
       "      <td>Immediately in front of the Main Building and ...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>128</td>\n",
       "      <td>270</td>\n",
       "      <td>False</td>\n",
       "      <td>semantic_chunks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   context_id chunk_id                                         chunk_text  \\\n",
       "0        1683   1683_0  Architecturally, the school has a Catholic cha...   \n",
       "1        1683   1683_1  Atop the Main Building's gold dome is a golden...   \n",
       "2        1683   1683_2  Immediately in front of the Main Building and ...   \n",
       "\n",
       "                                    chunk_embed_text  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Atop the Main Building's gold dome is a golden...   \n",
       "2  Immediately in front of the Main Building and ...   \n",
       "\n",
       "                      title  chunk_start  chunk_end  coref    chunking_type  \n",
       "0  University_of_Notre_Dame            0         53  False  semantic_chunks  \n",
       "1  University_of_Notre_Dame           54        127  False  semantic_chunks  \n",
       "2  University_of_Notre_Dame          128        270  False  semantic_chunks  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_semantic_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_semantic_train.to_excel(\"./data/prepared/squad_train_v2_semantic_chunking.xlsx\", index=False)\n",
    "df_semantic_val.to_excel(\"./data/prepared/squad_val_v2_semantic_chunking.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_df.to_excel(\"./data/prepared/squad_train_v2_queries.xlsx\", index=False)\n",
    "queries_df_val.to_excel(\"./data/prepared/squad_val_v2_queries.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "szakdoga",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
