{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "This notebook contains the code for data loading, preparation and chunking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_squad = squad[\"train\"]\n",
    "val_squad = squad[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_squad.to_pandas()\n",
    "val_df = val_squad.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Coreference Resolution Stub ----------\n",
    "def apply_coreference(text):\n",
    "    \"\"\"\n",
    "    Replace with actual coreference resolution model later.\n",
    "    For now, returns original text.\n",
    "    \"\"\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Sliding Window Chunking ----------\n",
    "def sliding_window_chunks(text, chunk_size=300, stride=100):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        chunks.append((text[start:end], start, end))\n",
    "        if end == len(text):\n",
    "            break\n",
    "        start += stride\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Semantic Chunking ----------\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def semantic_chunks(text, sim_threshold=0.6, max_chunk_size=500):\n",
    "    sentences = sent_tokenize(text)\n",
    "    # compute char offsets robustly\n",
    "    offsets = []\n",
    "    pos = 0\n",
    "    for s in sentences:\n",
    "        start = text.find(s, pos)\n",
    "        if start == -1:\n",
    "            start = pos\n",
    "        end = start + len(s)\n",
    "        offsets.append((s, start, end))\n",
    "        pos = end\n",
    "\n",
    "    if not offsets:\n",
    "        return []\n",
    "\n",
    "    sents = [s for (s, _, _) in offsets]\n",
    "    emb = model.encode(sents, convert_to_tensor=True)\n",
    "    chunks = []\n",
    "    cur_sents = [offsets[0]]\n",
    "    prev_emb = emb[0]\n",
    "\n",
    "    for i in range(1, len(offsets)):\n",
    "        sent, st, ed = offsets[i]\n",
    "        cur_emb = emb[i]\n",
    "        sim = util.cos_sim(prev_emb, cur_emb).item()\n",
    "        cur_text_len = offsets[i][2] - offsets[i - len(cur_sents)][1]\n",
    "\n",
    "        if sim >= sim_threshold and cur_text_len <= max_chunk_size:\n",
    "            cur_sents.append(offsets[i])\n",
    "        else:\n",
    "            start_char = cur_sents[0][1]\n",
    "            end_char = cur_sents[-1][2]\n",
    "            chunk_text = text[start_char:end_char]\n",
    "            chunks.append((chunk_text, start_char, end_char))\n",
    "            cur_sents = [offsets[i]]\n",
    "        prev_emb = cur_emb\n",
    "\n",
    "    if cur_sents:\n",
    "        start_char = cur_sents[0][1]\n",
    "        end_char = cur_sents[-1][2]\n",
    "        chunks.append((text[start_char:end_char], start_char, end_char))\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Answer Containment ----------\n",
    "def is_answer_in_chunk(chunk_text, answer_text):\n",
    "    return answer_text.lower().strip() in chunk_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Build Chunk DataFrame ----------\n",
    "def build_chunk_df(df, chunk_func, coref=False, **kwargs):\n",
    "    all_chunks = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        orig_context = row[\"context\"]\n",
    "        context = orig_context\n",
    "        if coref:\n",
    "            # For embeddings: resolved text; offsets stay on orig_context\n",
    "            resolved_context = apply_coreference(orig_context)\n",
    "            context_for_offsets = orig_context\n",
    "            context_for_embedding = resolved_context\n",
    "        else:\n",
    "            context_for_offsets = orig_context\n",
    "            context_for_embedding = orig_context\n",
    "\n",
    "        chunks_offsets = chunk_func(context_for_offsets, **kwargs)\n",
    "\n",
    "        for i, (chunk_text, start, end) in enumerate(chunks_offsets):\n",
    "            # chunk text for embedding (coref-resolved if coref=True)\n",
    "            chunk_embed_text = context_for_embedding[start:end]\n",
    "\n",
    "            for ans_text, ans_start in zip(row[\"answers\"][\"text\"], row[\"answers\"][\"answer_start\"]):\n",
    "                in_chunk = is_answer_in_chunk(chunk_text, ans_text)\n",
    "\n",
    "                all_chunks.append({\n",
    "                    \"context_id\": idx,\n",
    "                    \"chunk_id\": f\"{idx}_{i}\",\n",
    "                    \"chunk_text\": chunk_text,\n",
    "                    \"chunk_embed_text\": chunk_embed_text,\n",
    "                    \"title\": row.get(\"title\", \"\"),\n",
    "                    \"chunk_start\": start,\n",
    "                    \"chunk_end\": end,\n",
    "                    \"question\": row[\"question\"],\n",
    "                    \"answer_text\": ans_text,\n",
    "                    \"answer_start\": ans_start,\n",
    "                    \"answer_in_chunk\": in_chunk,\n",
    "                    \"coref\": coref,\n",
    "                    \"chunking_type\": chunk_func.__name__\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(all_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87599it [00:02, 29648.76it/s]\n",
      "10570it [00:00, 16452.77it/s]\n"
     ]
    }
   ],
   "source": [
    "df_sliding_train = build_chunk_df(train_df, sliding_window_chunks, coref=False, chunk_size=300, stride=100)\n",
    "df_sliding_val = build_chunk_df(val_df, sliding_window_chunks, coref=False, chunk_size=300, stride=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87599it [24:55, 58.58it/s] \n",
      "10570it [02:54, 60.72it/s]\n"
     ]
    }
   ],
   "source": [
    "df_semantic_train = build_chunk_df(train_df, semantic_chunks, coref=False, sim_threshold=0.6, max_chunk_size=500)\n",
    "df_semantic_val = build_chunk_df(val_df, semantic_chunks, coref=False, sim_threshold=0.6, max_chunk_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sliding_coref = build_chunk_df(train_df, sliding_window_chunks, coref=True, chunk_size=300, stride=100)\n",
    "#df_semantic_coref = build_chunk_df(train_df, semantic_chunks, coref=True, sim_threshold=0.6, max_chunk_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Quick Check ----------\n",
    "print(\"Sliding train:\", df_sliding_train.shape)\n",
    "print(\"Semantic train:\", df_semantic_train.shape)\n",
    "#print(\"Sliding+Coref:\", df_sliding_coref.shape)\n",
    "#print(\"Semantic+Coref:\", df_semantic_coref.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk_text</th>\n",
       "      <th>chunk_embed_text</th>\n",
       "      <th>chunk_start</th>\n",
       "      <th>chunk_end</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_in_chunk</th>\n",
       "      <th>coref</th>\n",
       "      <th>chunking_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>semantic_chunks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0_1</td>\n",
       "      <td>Atop the Main Building's gold dome is a golden...</td>\n",
       "      <td>Atop the Main Building's gold dome is a golden...</td>\n",
       "      <td>54</td>\n",
       "      <td>127</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>semantic_chunks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0_2</td>\n",
       "      <td>Immediately in front of the Main Building and ...</td>\n",
       "      <td>Immediately in front of the Main Building and ...</td>\n",
       "      <td>128</td>\n",
       "      <td>270</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>semantic_chunks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   context_id chunk_id                                         chunk_text  \\\n",
       "0           0      0_0  Architecturally, the school has a Catholic cha...   \n",
       "1           0      0_1  Atop the Main Building's gold dome is a golden...   \n",
       "2           0      0_2  Immediately in front of the Main Building and ...   \n",
       "\n",
       "                                    chunk_embed_text  chunk_start  chunk_end  \\\n",
       "0  Architecturally, the school has a Catholic cha...            0         53   \n",
       "1  Atop the Main Building's gold dome is a golden...           54        127   \n",
       "2  Immediately in front of the Main Building and ...          128        270   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  To whom did the Virgin Mary allegedly appear i...   \n",
       "2  To whom did the Virgin Mary allegedly appear i...   \n",
       "\n",
       "                  answer_text  answer_start  answer_in_chunk  coref  \\\n",
       "0  Saint Bernadette Soubirous           515            False  False   \n",
       "1  Saint Bernadette Soubirous           515            False  False   \n",
       "2  Saint Bernadette Soubirous           515            False  False   \n",
       "\n",
       "     chunking_type  \n",
       "0  semantic_chunks  \n",
       "1  semantic_chunks  \n",
       "2  semantic_chunks  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_semantic_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk_text</th>\n",
       "      <th>chunk_embed_text</th>\n",
       "      <th>chunk_start</th>\n",
       "      <th>chunk_end</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_in_chunk</th>\n",
       "      <th>coref</th>\n",
       "      <th>chunking_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>sliding_window_chunks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0_1</td>\n",
       "      <td>statue of the Virgin Mary. Immediately in fro...</td>\n",
       "      <td>statue of the Virgin Mary. Immediately in fro...</td>\n",
       "      <td>100</td>\n",
       "      <td>400</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>sliding_window_chunks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0_2</td>\n",
       "      <td>tue of Christ with arms upraised with the lege...</td>\n",
       "      <td>tue of Christ with arms upraised with the lege...</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>sliding_window_chunks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   context_id chunk_id                                         chunk_text  \\\n",
       "0           0      0_0  Architecturally, the school has a Catholic cha...   \n",
       "1           0      0_1   statue of the Virgin Mary. Immediately in fro...   \n",
       "2           0      0_2  tue of Christ with arms upraised with the lege...   \n",
       "\n",
       "                                    chunk_embed_text  chunk_start  chunk_end  \\\n",
       "0  Architecturally, the school has a Catholic cha...            0        300   \n",
       "1   statue of the Virgin Mary. Immediately in fro...          100        400   \n",
       "2  tue of Christ with arms upraised with the lege...          200        500   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  To whom did the Virgin Mary allegedly appear i...   \n",
       "2  To whom did the Virgin Mary allegedly appear i...   \n",
       "\n",
       "                  answer_text  answer_start  answer_in_chunk  coref  \\\n",
       "0  Saint Bernadette Soubirous           515            False  False   \n",
       "1  Saint Bernadette Soubirous           515            False  False   \n",
       "2  Saint Bernadette Soubirous           515            False  False   \n",
       "\n",
       "           chunking_type  \n",
       "0  sliding_window_chunks  \n",
       "1  sliding_window_chunks  \n",
       "2  sliding_window_chunks  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sliding_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_semantic_train.to_excel(\"./data/prepared/squad_train_v1_semantic_chunking.xlsx\", index=False)\n",
    "df_semantic_val.to_excel(\"./data/prepared/squad_val_v1_semantic_chunking.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tdk_szakdoga",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
