{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "\n",
    "This notebook contains the code for the retrival pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CZB3BP\\.conda\\envs\\szakdoga\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "from OnlineKMeans import OnlineKMeans\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cluster_centroids(chunk_embeddings, cluster_labels):\n",
    "    \"\"\"\n",
    "    Compute centroids once for all clusters.\n",
    "    Returns:\n",
    "        centroid_matrix: np.ndarray of shape (n_clusters, embedding_dim)\n",
    "        centroid_ids: list of cluster IDs\n",
    "    \"\"\"\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "    cluster_centroids = {\n",
    "        cid: chunk_embeddings[cluster_labels == cid].mean(axis=0)\n",
    "        for cid in unique_clusters\n",
    "    }\n",
    "    centroid_matrix = np.vstack(list(cluster_centroids.values()))\n",
    "    centroid_ids = list(cluster_centroids.keys())\n",
    "    return centroid_matrix, centroid_ids\n",
    "\n",
    "\n",
    "def retrieve_top_chunks_by_cluster(\n",
    "    query_embedding,\n",
    "    chunk_embeddings,\n",
    "    df_chunks,\n",
    "    cluster_labels,\n",
    "    centroid_matrix,\n",
    "    centroid_ids,\n",
    "    top_n_clusters=2,\n",
    "    top_k_total=5\n",
    "):\n",
    "    # --- Use precomputed centroids ---\n",
    "    cluster_sims = cosine_similarity([query_embedding], centroid_matrix)[0]\n",
    "    top_n_idx = cluster_sims.argsort()[::-1][:top_n_clusters]\n",
    "    selected_clusters = [centroid_ids[i] for i in top_n_idx]\n",
    "\n",
    "    # Collect all chunks from selected clusters\n",
    "    mask = np.isin(cluster_labels, selected_clusters)\n",
    "    selected_chunk_embeddings = chunk_embeddings[mask]\n",
    "    selected_df = df_chunks[mask].reset_index(drop=True)\n",
    "\n",
    "    # Compute similarity for all these chunks\n",
    "    sims = cosine_similarity([query_embedding], selected_chunk_embeddings)[0]\n",
    "\n",
    "    # Get top-K chunks overall\n",
    "    top_k_idx = sims.argsort()[::-1][:top_k_total]\n",
    "    results = []\n",
    "\n",
    "    for idx in top_k_idx:\n",
    "        results.append({\n",
    "            \"cluster\": cluster_labels[mask][idx],\n",
    "            \"context_id\": selected_df.iloc[idx][\"context_id\"],\n",
    "            \"chunk_id\": selected_df.iloc[idx][\"chunk_id\"],\n",
    "            \"title\": selected_df.iloc[idx][\"title\"],\n",
    "            \"chunk_embed_text\": selected_df.iloc[idx][\"chunk_embed_text\"],\n",
    "            \"chunk_start\": selected_df.iloc[idx][\"chunk_start\"],\n",
    "            \"chunk_end\": selected_df.iloc[idx][\"chunk_end\"],\n",
    "            \"similarity\": sims[idx]\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results).sort_values(\"similarity\", ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_top_chunks_full(\n",
    "    query_embedding,\n",
    "    chunk_embeddings,\n",
    "    df_chunks,\n",
    "    top_k_chunks=10\n",
    "):\n",
    "    sims = cosine_similarity([query_embedding], chunk_embeddings)[0]\n",
    "    top_idx = sims.argsort()[::-1][:top_k_chunks]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_idx:\n",
    "        results.append({\n",
    "            \"context_id\": df_chunks.iloc[idx][\"context_id\"],\n",
    "            \"chunk_id\": df_chunks.iloc[idx][\"chunk_id\"],\n",
    "            \"title\": df_chunks.iloc[idx][\"title\"],\n",
    "            \"chunk_embed_text\": df_chunks.iloc[idx][\"chunk_embed_text\"],\n",
    "            \"chunk_start\": df_chunks.iloc[idx][\"chunk_start\"],\n",
    "            \"chunk_end\": df_chunks.iloc[idx][\"chunk_end\"],\n",
    "            \"similarity\": sims[idx]\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results).sort_values(\"similarity\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------- Answer Containment ----------\n",
    "# def is_answer_in_chunk(chunk_text, answer_text):\n",
    "#     return answer_text.lower().strip() in chunk_text.lower()\n",
    "\n",
    "# def is_answer_in_chunk(chunk_text, answer_text):\n",
    "#     # Normalize\n",
    "#     chunk_tokens = set(re.findall(r\"\\w+\", chunk_text.lower()))\n",
    "#     answer_tokens = set(re.findall(r\"\\w+\", answer_text.lower()))\n",
    "\n",
    "#     # Require that most/all answer tokens are present\n",
    "#     return len(answer_tokens & chunk_tokens) / max(1, len(answer_tokens)) >= 0.8\n",
    "\n",
    "\n",
    "# from rapidfuzz import fuzz\n",
    "\n",
    "# def is_answer_in_chunk(chunk_text, answer_text, threshold=80):\n",
    "#     score = fuzz.partial_ratio(answer_text.lower(), chunk_text.lower())\n",
    "#     return score >= threshold\n",
    "\n",
    "def is_answer_in_chunk(answer_start, chunk_start, chunk_length):\n",
    "    if answer_start is None or chunk_start is None or chunk_length is None:\n",
    "        return False\n",
    "    return chunk_start <= answer_start < (chunk_start + chunk_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_for_query(results, query_row, similarity_threshold=0.6):\n",
    "    # --- Check similarity threshold ---\n",
    "    if results.empty or results[\"similarity\"].max() < similarity_threshold:\n",
    "        results_filtered = pd.DataFrame([])  # Treat as no answer\n",
    "    else:\n",
    "        results_filtered = results\n",
    "\n",
    "    # --- Document-level ---\n",
    "    answer_exists = pd.notna(query_row[\"answer_start\"])\n",
    "    found_doc_id = False if results_filtered.empty else any(\n",
    "        query_row[\"context_id\"] == doc_id for doc_id in results_filtered[\"context_id\"]\n",
    "    )\n",
    "    y_true_doc = 1 if answer_exists else 0\n",
    "    y_pred_doc = 1 if found_doc_id else 0\n",
    "\n",
    "    # --- Chunk-level ---\n",
    "    if results_filtered.empty:\n",
    "        found_chunk_context = False\n",
    "        good_chunks = 0\n",
    "    else:\n",
    "        correct_doc_chunks = results_filtered[results_filtered[\"context_id\"] == query_row[\"context_id\"]]\n",
    "        found_chunk_context = any(\n",
    "            is_answer_in_chunk(\n",
    "                query_row[\"answer_start\"],\n",
    "                chunk[\"chunk_start\"],\n",
    "                chunk[\"chunk_end\"] - chunk[\"chunk_start\"]\n",
    "            )\n",
    "            for _, chunk in results_filtered.iterrows()\n",
    "        )\n",
    "        good_chunks = len(correct_doc_chunks)\n",
    "\n",
    "    total_chunks = results_filtered.shape[0] if not results_filtered.empty else 1\n",
    "    chunk_ratio = good_chunks / total_chunks\n",
    "\n",
    "    y_true_chunk = 1 if answer_exists else 0\n",
    "    y_pred_chunk = 1 if found_chunk_context else 0\n",
    "\n",
    "    return y_true_doc, y_pred_doc, y_true_chunk, y_pred_chunk, chunk_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_top_k_accuracy(\n",
    "#     df_queries,\n",
    "#     chunk_embeddings,\n",
    "#     df_chunks,\n",
    "#     cluster_labels,\n",
    "#     top_n_clusters=2,\n",
    "#     top_k_total=5\n",
    "# ):\n",
    "#     # ✅ Compute centroids once\n",
    "#     centroid_matrix, centroid_ids = compute_cluster_centroids(chunk_embeddings, cluster_labels)\n",
    "\n",
    "#     y_true_doc = []\n",
    "#     y_pred_doc = []\n",
    "\n",
    "#     y_true_chunk = []\n",
    "#     y_pred_chunk = []\n",
    "\n",
    "#     chunk_ratios = []\n",
    "\n",
    "#     for i, row in tqdm(df_queries.iterrows(), total=len(df_queries)):\n",
    "#         query_emb = model.encode([row[\"question\"]])[0]\n",
    "#         results = retrieve_top_chunks_by_cluster(\n",
    "#             query_embedding=query_emb,\n",
    "#             chunk_embeddings=chunk_embeddings,\n",
    "#             df_chunks=df_chunks,\n",
    "#             cluster_labels=cluster_labels,\n",
    "#             centroid_matrix=centroid_matrix,\n",
    "#             centroid_ids=centroid_ids,\n",
    "#             top_n_clusters=top_n_clusters,\n",
    "#             top_k_total=top_k_total\n",
    "#         )\n",
    "\n",
    "#         # Document-level\n",
    "#         found_doc_id = any(row[\"context_id\"] == doc_id for doc_id in results[\"context_id\"])\n",
    "#         y_true_doc.append(1)\n",
    "#         y_pred_doc.append(1 if found_doc_id else 0)\n",
    "\n",
    "#         correct_doc_chunks = results[results[\"context_id\"] == row[\"context_id\"]]\n",
    "#         found_chunk_context = any(\n",
    "#             is_answer_in_chunk(\n",
    "#                 row[\"answer_start\"],\n",
    "#                 chunk[\"chunk_start\"],\n",
    "#                 chunk[\"chunk_end\"] - chunk[\"chunk_start\"]\n",
    "#             )\n",
    "#             for _, chunk in correct_doc_chunks.iterrows()\n",
    "#         )\n",
    "#         good_chunks = len(correct_doc_chunks)\n",
    "#         total_chunks = results.shape[0]\n",
    "#         ratio = good_chunks / total_chunks\n",
    "#         chunk_ratios.append(ratio)\n",
    "\n",
    "#         y_true_chunk.append(1)\n",
    "#         y_pred_chunk.append(1 if found_chunk_context else 0)\n",
    "\n",
    "#     # Compute metrics\n",
    "#     chunk_accuracy = sum(chunk_ratios) / len(chunk_ratios) if len(chunk_ratios) > 0 else 0\n",
    "#     metrics = {\n",
    "#         \"doc_accuracy\": sum(y_pred_doc) / len(y_pred_doc),\n",
    "#         \"chunk_accuracy\": sum(y_pred_chunk) / len(y_pred_chunk),\n",
    "#         \"doc_precision\": precision_score(y_true_doc, y_pred_doc, zero_division=0),\n",
    "#         \"doc_recall\": recall_score(y_true_doc, y_pred_doc, zero_division=0),\n",
    "#         \"doc_f1\": f1_score(y_true_doc, y_pred_doc, zero_division=0),\n",
    "#         \"chunk_precision\": precision_score(y_true_chunk, y_pred_chunk, zero_division=0),\n",
    "#         \"chunk_recall\": recall_score(y_true_chunk, y_pred_chunk, zero_division=0),\n",
    "#         \"chunk_f1\": f1_score(y_true_chunk, y_pred_chunk, zero_division=0),\n",
    "#         \"correct_chunk_accuracy\": chunk_accuracy\n",
    "#     }\n",
    "\n",
    "#     return metrics\n",
    "def evaluate_top_k_accuracy(\n",
    "    df_queries,\n",
    "    chunk_embeddings,\n",
    "    df_chunks,\n",
    "    cluster_labels,\n",
    "    top_n_clusters=2,\n",
    "    top_k_total=5\n",
    "):\n",
    "    # Compute centroids once\n",
    "    centroid_matrix, centroid_ids = compute_cluster_centroids(chunk_embeddings, cluster_labels)\n",
    "\n",
    "    y_true_doc = []\n",
    "    y_pred_doc = []\n",
    "\n",
    "    y_true_chunk = []\n",
    "    y_pred_chunk = []\n",
    "\n",
    "    chunk_ratios = []\n",
    "\n",
    "    for _, row in tqdm(df_queries.iterrows(), total=len(df_queries)):\n",
    "        query_emb = model.encode([row[\"question\"]])[0]\n",
    "        results = retrieve_top_chunks_by_cluster(\n",
    "            query_embedding=query_emb,\n",
    "            chunk_embeddings=chunk_embeddings,\n",
    "            df_chunks=df_chunks,\n",
    "            cluster_labels=cluster_labels,\n",
    "            centroid_matrix=centroid_matrix,\n",
    "            centroid_ids=centroid_ids,\n",
    "            top_n_clusters=top_n_clusters,\n",
    "            top_k_total=top_k_total\n",
    "        )\n",
    "\n",
    "        ytd, ypd, ytc, ypc, cr = compute_metrics_for_query(results, row)\n",
    "        y_true_doc.append(ytd)\n",
    "        y_pred_doc.append(ypd)\n",
    "        y_true_chunk.append(ytc)\n",
    "        y_pred_chunk.append(ypc)\n",
    "        chunk_ratios.append(cr)\n",
    "\n",
    "    # Convert to arrays\n",
    "    y_true_doc_arr = np.array(y_true_doc)\n",
    "    y_pred_doc_arr = np.array(y_pred_doc)\n",
    "    y_true_chunk_arr = np.array(y_true_chunk)\n",
    "    y_pred_chunk_arr = np.array(y_pred_chunk)\n",
    "\n",
    "    # Compute metrics\n",
    "    chunk_accuracy = sum(chunk_ratios) / len(chunk_ratios) if len(chunk_ratios) > 0 else 0\n",
    "\n",
    "    metrics = {\n",
    "        \"doc_accuracy\": (y_pred_doc_arr == y_true_doc_arr).mean(),\n",
    "        \"chunk_accuracy\": (y_pred_chunk_arr == y_true_chunk_arr).mean(),\n",
    "        \"doc_precision\": precision_score(y_true_doc_arr, y_pred_doc_arr, zero_division=0),\n",
    "        \"doc_recall\": recall_score(y_true_doc_arr, y_pred_doc_arr, zero_division=0),\n",
    "        \"doc_f1\": f1_score(y_true_doc_arr, y_pred_doc_arr, zero_division=0),\n",
    "        \"chunk_precision\": precision_score(y_true_chunk_arr, y_pred_chunk_arr, zero_division=0),\n",
    "        \"chunk_recall\": recall_score(y_true_chunk_arr, y_pred_chunk_arr, zero_division=0),\n",
    "        \"chunk_f1\": f1_score(y_true_chunk_arr, y_pred_chunk_arr, zero_division=0),\n",
    "        \"correct_chunk_accuracy\": chunk_accuracy,\n",
    "        # True/False Positives/Negatives\n",
    "        \"doc_true_positives\": np.sum((y_pred_doc_arr == 1) & (y_true_doc_arr == 1)),\n",
    "        \"doc_true_negatives\": np.sum((y_pred_doc_arr == 0) & (y_true_doc_arr == 0)),\n",
    "        \"doc_false_positives\": np.sum((y_pred_doc_arr == 1) & (y_true_doc_arr == 0)),\n",
    "        \"doc_false_negatives\": np.sum((y_pred_doc_arr == 0) & (y_true_doc_arr == 1)),\n",
    "        \"chunk_true_positives\": np.sum((y_pred_chunk_arr == 1) & (y_true_chunk_arr == 1)),\n",
    "        \"chunk_true_negatives\": np.sum((y_pred_chunk_arr == 0) & (y_true_chunk_arr == 0)),\n",
    "        \"chunk_false_positives\": np.sum((y_pred_chunk_arr == 1) & (y_true_chunk_arr == 0)),\n",
    "        \"chunk_false_negatives\": np.sum((y_pred_chunk_arr == 0) & (y_true_chunk_arr == 1)),\n",
    "    }\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_top_k_accuracy_full(df_queries, chunk_embeddings, df_chunks, top_k_chunks=5, similarity_threshold=0.6):\n",
    "    # y_true_doc = []\n",
    "    # y_pred_doc = []\n",
    "\n",
    "    # y_true_chunk = []\n",
    "    # y_pred_chunk = []\n",
    "\n",
    "    # chunk_ratios = []\n",
    "\n",
    "    # for i, row in tqdm(df_queries.iterrows(), total=len(df_queries)):\n",
    "    #     query_emb = model.encode([row[\"question\"]])[0]\n",
    "    #     results = retrieve_top_chunks_full(\n",
    "    #         query_embedding=query_emb,\n",
    "    #         chunk_embeddings=chunk_embeddings,\n",
    "    #         df_chunks=df_chunks,\n",
    "    #         top_k_chunks=top_k_chunks\n",
    "    #     )\n",
    "\n",
    "    #     # Document-level\n",
    "    #     found_doc_id = any(row[\"context_id\"] == doc_id for doc_id in results[\"context_id\"])\n",
    "    #     y_true_doc.append(1)\n",
    "    #     y_pred_doc.append(1 if found_doc_id else 0)\n",
    "\n",
    "    #     correct_doc_chunks = results[results[\"context_id\"] == row[\"context_id\"]]\n",
    "    #     found_chunk_context = any(\n",
    "    #         is_answer_in_chunk(\n",
    "    #             row[\"answer_start\"],\n",
    "    #             chunk[\"chunk_start\"],\n",
    "    #             chunk[\"chunk_end\"] - chunk[\"chunk_start\"]\n",
    "    #         )\n",
    "    #         for _, chunk in correct_doc_chunks.iterrows()\n",
    "    #     )\n",
    "    #     good_chunks = len(correct_doc_chunks)\n",
    "    #     total_chunks = results.shape[0]\n",
    "    #     ratio = good_chunks / total_chunks\n",
    "    #     chunk_ratios.append(ratio)\n",
    "\n",
    "    #     y_true_chunk.append(1)\n",
    "    #     y_pred_chunk.append(1 if found_chunk_context else 0)\n",
    "\n",
    "    # # Compute metrics\n",
    "    # chunk_accuracy = sum(chunk_ratios) / len(chunk_ratios) if len(chunk_ratios) > 0 else 0\n",
    "    # metrics = {\n",
    "    #     \"doc_accuracy\": sum(y_pred_doc) / len(y_pred_doc),\n",
    "    #     \"chunk_accuracy\": sum(y_pred_chunk) / len(y_pred_chunk),\n",
    "    #     \"doc_precision\": precision_score(y_true_doc, y_pred_doc, zero_division=0),\n",
    "    #     \"doc_recall\": recall_score(y_true_doc, y_pred_doc, zero_division=0),\n",
    "    #     \"doc_f1\": f1_score(y_true_doc, y_pred_doc, zero_division=0),\n",
    "    #     \"chunk_precision\": precision_score(y_true_chunk, y_pred_chunk, zero_division=0),\n",
    "    #     \"chunk_recall\": recall_score(y_true_chunk, y_pred_chunk, zero_division=0),\n",
    "    #     \"chunk_f1\": f1_score(y_true_chunk, y_pred_chunk, zero_division=0),\n",
    "    #     \"correct_chunk_accuracy\": chunk_accuracy\n",
    "    # }\n",
    "\n",
    "    # return metrics\n",
    "def evaluate_top_k_accuracy_full(df_queries, chunk_embeddings, df_chunks, top_k_chunks=5):\n",
    "    y_true_doc = []\n",
    "    y_pred_doc = []\n",
    "\n",
    "    y_true_chunk = []\n",
    "    y_pred_chunk = []\n",
    "\n",
    "    chunk_ratios = []\n",
    "\n",
    "    for _, row in tqdm(df_queries.iterrows(), total=len(df_queries)):\n",
    "        query_emb = model.encode([row[\"question\"]])[0]\n",
    "        results = retrieve_top_chunks_full(\n",
    "            query_embedding=query_emb,\n",
    "            chunk_embeddings=chunk_embeddings,\n",
    "            df_chunks=df_chunks,\n",
    "            top_k_chunks=top_k_chunks\n",
    "        )\n",
    "\n",
    "        ytd, ypd, ytc, ypc, cr = compute_metrics_for_query(results, row)\n",
    "        y_true_doc.append(ytd)\n",
    "        y_pred_doc.append(ypd)\n",
    "        y_true_chunk.append(ytc)\n",
    "        y_pred_chunk.append(ypc)\n",
    "        chunk_ratios.append(cr)\n",
    "\n",
    "    # Convert to arrays\n",
    "    y_true_doc_arr = np.array(y_true_doc)\n",
    "    y_pred_doc_arr = np.array(y_pred_doc)\n",
    "    y_true_chunk_arr = np.array(y_true_chunk)\n",
    "    y_pred_chunk_arr = np.array(y_pred_chunk)\n",
    "\n",
    "    # Compute metrics\n",
    "    chunk_accuracy = sum(chunk_ratios) / len(chunk_ratios) if len(chunk_ratios) > 0 else 0\n",
    "\n",
    "    metrics = {\n",
    "        \"doc_accuracy\": (y_pred_doc_arr == y_true_doc_arr).mean(),\n",
    "        \"chunk_accuracy\": (y_pred_chunk_arr == y_true_chunk_arr).mean(),\n",
    "        \"doc_precision\": precision_score(y_true_doc_arr, y_pred_doc_arr, zero_division=0),\n",
    "        \"doc_recall\": recall_score(y_true_doc_arr, y_pred_doc_arr, zero_division=0),\n",
    "        \"doc_f1\": f1_score(y_true_doc_arr, y_pred_doc_arr, zero_division=0),\n",
    "        \"chunk_precision\": precision_score(y_true_chunk_arr, y_pred_chunk_arr, zero_division=0),\n",
    "        \"chunk_recall\": recall_score(y_true_chunk_arr, y_pred_chunk_arr, zero_division=0),\n",
    "        \"chunk_f1\": f1_score(y_true_chunk_arr, y_pred_chunk_arr, zero_division=0),\n",
    "        \"correct_chunk_accuracy\": chunk_accuracy,\n",
    "        # True/False Positives/Negatives\n",
    "        \"doc_true_positives\": np.sum((y_pred_doc_arr == 1) & (y_true_doc_arr == 1)),\n",
    "        \"doc_true_negatives\": np.sum((y_pred_doc_arr == 0) & (y_true_doc_arr == 0)),\n",
    "        \"doc_false_positives\": np.sum((y_pred_doc_arr == 1) & (y_true_doc_arr == 0)),\n",
    "        \"doc_false_negatives\": np.sum((y_pred_doc_arr == 0) & (y_true_doc_arr == 1)),\n",
    "        \"chunk_true_positives\": np.sum((y_pred_chunk_arr == 1) & (y_true_chunk_arr == 1)),\n",
    "        \"chunk_true_negatives\": np.sum((y_pred_chunk_arr == 0) & (y_true_chunk_arr == 0)),\n",
    "        \"chunk_false_positives\": np.sum((y_pred_chunk_arr == 1) & (y_true_chunk_arr == 0)),\n",
    "        \"chunk_false_negatives\": np.sum((y_pred_chunk_arr == 0) & (y_true_chunk_arr == 1)),\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatchkmeans_retrieval_evaluation(\n",
    "    chunk_embeddings,\n",
    "    df_chunks,\n",
    "    df_queries,\n",
    "    n_clusters=20,\n",
    "    batch_size=500,\n",
    "    top_k_total=5,\n",
    "    init_fraction=0.1\n",
    "):\n",
    "    n_samples = chunk_embeddings.shape[0]\n",
    "    n_batches = int(np.ceil(n_samples / batch_size))\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # --- Inicializáló klaszterezés ---\n",
    "    init_start = time.time()\n",
    "    init_size = max(1, int(n_samples * init_fraction))\n",
    "    kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=42, batch_size=batch_size)\n",
    "    kmeans.partial_fit(chunk_embeddings[:init_size])\n",
    "    init_end = time.time()\n",
    "    init_time = init_end - init_start\n",
    "\n",
    "    print(\"Start batch processing...\")\n",
    "    for batch_idx in tqdm(range(1, n_batches + 1)):\n",
    "        start_idx = (batch_idx - 1) * batch_size\n",
    "        end_idx = min(batch_idx * batch_size, n_samples)\n",
    "        X_batch = chunk_embeddings[start_idx:end_idx]\n",
    "\n",
    "        # --- Online update ---\n",
    "        update_start = time.time()\n",
    "        kmeans.partial_fit(X_batch)\n",
    "        update_end = time.time()\n",
    "        update_time = update_end - update_start\n",
    "\n",
    "        # --- Klasztercímkék frissítése ---\n",
    "        labels = kmeans.predict(chunk_embeddings)\n",
    "\n",
    "        # --- Retrieval + pontosság ---\n",
    "        retrieval_start = time.time()\n",
    "        metrics = evaluate_top_k_accuracy(\n",
    "            df_queries=df_queries,\n",
    "            chunk_embeddings=chunk_embeddings,\n",
    "            df_chunks=df_chunks,\n",
    "            cluster_labels=labels,\n",
    "            top_n_clusters=5,\n",
    "            top_k_total=top_k_total\n",
    "        )\n",
    "        retrieval_end = time.time()\n",
    "        retrieval_time = retrieval_end - retrieval_start\n",
    "\n",
    "        results.append({\n",
    "            \"batch\": batch_idx,\n",
    "            \"init_time\": init_time if batch_idx == 1 else 0,\n",
    "            \"update_time\": update_time,\n",
    "            \"retrieval_time\": retrieval_time,\n",
    "            \"metrics\": metrics,\n",
    "        })\n",
    "        print(f\"[Batch {batch_idx}/{n_batches}] Doc acc: {metrics['doc_accuracy']:.4f}, Chunk acc: {metrics['chunk_accuracy']:.4f}\")\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_kmeans_retrieval_evaluation(\n",
    "    chunk_embeddings,\n",
    "    df_chunks,\n",
    "    df_queries,\n",
    "    n_clusters=20,\n",
    "    batch_size=500,\n",
    "    top_k_total=5,\n",
    "    init_fraction=0.5,  # fraction of data used for initialization\n",
    "    max_clusters=None,\n",
    "    metric=\"cosine\",\n",
    "    new_cluster_threshold=None,\n",
    "    merge_threshold=None,\n",
    "    decay=None\n",
    "):\n",
    "    \"\"\"\n",
    "    OnlineKMeans clustering + retrieval evaluation on growing dataset.\n",
    "    Only evaluates on the chunks that have been clustered so far.\n",
    "    \"\"\"\n",
    "\n",
    "    n_samples = chunk_embeddings.shape[0]\n",
    "    init_size = int(n_samples * init_fraction)\n",
    "    remaining_size = n_samples - init_size\n",
    "\n",
    "    # --- Step 1: Initialization ---\n",
    "    print(f\"🔧 Using {init_fraction*100:.0f}% of data ({init_size} samples) for initialization\")\n",
    "    init_start = time.time()\n",
    "    okm = OnlineKMeans(\n",
    "        n_clusters=n_clusters,\n",
    "        max_clusters=max_clusters,\n",
    "        metric=metric,\n",
    "        new_cluster_threshold=new_cluster_threshold,\n",
    "        merge_threshold=merge_threshold,\n",
    "        random_state=42,\n",
    "        decay=decay\n",
    "    )\n",
    "    okm.partial_fit(chunk_embeddings[:init_size])\n",
    "    init_end = time.time()\n",
    "    init_time = init_end - init_start\n",
    "    print(f\"✅ Initialization done in {init_time:.4f} s\")\n",
    "\n",
    "    # --- Step 2: Online updates on the remaining data ---\n",
    "    results = []\n",
    "    for batch_idx in tqdm(range(1, int(np.ceil(remaining_size / batch_size)) + 1)):\n",
    "        start_idx = (batch_idx - 1) * batch_size\n",
    "        end_idx = min(batch_idx * batch_size, remaining_size)\n",
    "        batch_embeddings = chunk_embeddings[init_size + start_idx : init_size + end_idx]\n",
    "\n",
    "        # --- Online update ---\n",
    "        update_start = time.time()\n",
    "        okm.partial_fit(batch_embeddings)\n",
    "        update_end = time.time()\n",
    "        update_time = update_end - update_start\n",
    "\n",
    "        # --- Only evaluate on seen data so far ---\n",
    "        seen_end_idx = init_size + end_idx\n",
    "        seen_embeddings = chunk_embeddings[:seen_end_idx]\n",
    "        seen_df_chunks = df_chunks.iloc[:seen_end_idx].reset_index(drop=True)\n",
    "\n",
    "        # --- Predict cluster labels for seen data ---\n",
    "        labels_seen = okm.predict(seen_embeddings)\n",
    "\n",
    "        # --- Filter queries to only those with seen context_ids ---\n",
    "        df_queries_seen = df_queries[df_queries[\"context_id\"].isin(seen_df_chunks[\"context_id\"].unique())].reset_index(drop=True)\n",
    "        print(f\"df_queries_seen: {df_queries_seen.shape[0]}, seen_df_chunks: {seen_df_chunks.shape[0]}\")\n",
    "\n",
    "        # --- Retrieval accuracy ---\n",
    "        retrieval_start = time.time()\n",
    "        metrics = evaluate_top_k_accuracy(\n",
    "            df_queries=df_queries_seen,\n",
    "            chunk_embeddings=seen_embeddings,\n",
    "            df_chunks=seen_df_chunks,\n",
    "            cluster_labels=labels_seen,\n",
    "            top_n_clusters=5,\n",
    "            top_k_total=top_k_total\n",
    "        )\n",
    "        retrieval_end = time.time()\n",
    "        retrieval_time = retrieval_end - retrieval_start\n",
    "\n",
    "        results.append({\n",
    "            \"batch\": batch_idx,\n",
    "            \"init_time\": init_time if batch_idx == 1 else 0,\n",
    "            \"update_time\": update_time,\n",
    "            \"retrieval_time\": retrieval_time,\n",
    "            \"metrics\": metrics,\n",
    "            \"n_clusters\": len(okm.centroids)\n",
    "        })\n",
    "\n",
    "        print(f\"[Batch {batch_idx}] Seen chunks: {seen_end_idx}, Doc acc: {metrics['doc_accuracy']:.4f}, Chunk acc: {metrics['chunk_accuracy']:.4f}, Clusters: {len(okm.centroids)}\")\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_excel(\"../data/labelled/squad_train_v2_semantic_chunking_clustered.xlsx\")\n",
    "df_queries_train = pd.read_excel(\"../data/prepared/squad_train_v2_queries.xlsx\")\n",
    "\n",
    "X_train = np.load(\"../data/tensors/squad_train_v4_semantic_chunking_l2.npy\")\n",
    "\n",
    "labels_train = df_train[\"cluster\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84007, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87599, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_queries_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How much did Beyonce initially contribute to the foundation?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_queries_train.loc[1000, \"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = df_queries_train.loc[1000, \"question\"]\n",
    "query_emb = model.encode([query])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 0.00597 seconds\n",
      "Cluster-based retrieval:\n",
      "['Rolling Stone reported that the music industry was urging them to return the money they earned for the concerts; a spokesperson for Beyoncé later confirmed to The Huffington Post that she donated the money to the Clinton Bush Haiti Fund.', 'After Hurricane Katrina in 2005, Beyoncé and Rowland founded the Survivor Foundation to provide transitional housing for victims in the Houston area, to which Beyoncé contributed an initial $250,000.', 'Beyoncé would later speak of her mother as the person who helped her fight it.']\n"
     ]
    }
   ],
   "source": [
    "centroid_matrix, centroid_ids = compute_cluster_centroids(X_train, labels_train)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "top_chunks_cluster = retrieve_top_chunks_by_cluster(\n",
    "    query_embedding=query_emb,\n",
    "    chunk_embeddings=X_train,\n",
    "    df_chunks=df_train,\n",
    "    cluster_labels=labels_train,\n",
    "    top_n_clusters=1,\n",
    "    top_k_total=3,\n",
    "    centroid_matrix=centroid_matrix,\n",
    "    centroid_ids=centroid_ids\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Runtime: {elapsed_time:.5f} seconds\")\n",
    "print(\"Cluster-based retrieval:\")\n",
    "print(top_chunks_cluster['chunk_embed_text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 0.26332 seconds\n",
      "Full retrieval:\n",
      "['Rolling Stone reported that the music industry was urging them to return the money they earned for the concerts; a spokesperson for Beyoncé later confirmed to The Huffington Post that she donated the money to the Clinton Bush Haiti Fund.', 'After Hurricane Katrina in 2005, Beyoncé and Rowland founded the Survivor Foundation to provide transitional housing for victims in the Houston area, to which Beyoncé contributed an initial $250,000.', 'See: List of wealthiest foundations.']\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "top_chunks_full = retrieve_top_chunks_full(\n",
    "    query_embedding=query_emb,\n",
    "    chunk_embeddings=X_train,\n",
    "    df_chunks=df_train,\n",
    "    top_k_chunks=3\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Runtime: {elapsed_time:.5f} seconds\")\n",
    "print(\"Full retrieval:\")\n",
    "print(top_chunks_full['chunk_embed_text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation for retrival with cluster centroids vs full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_semantic_train = np.load(\"../data/tensors/squad_train_v2_semantic_chunking_l2.npy\")\n",
    "df_semantic_train = pd.read_excel(\"../data/labelled/squad_train_v2_semantic_chunking_clustered.xlsx\")\n",
    "df_queries_train = pd.read_excel(\"../data/prepared/squad_train_v2_queries.xlsx\")\n",
    "\n",
    "labels_train = df_semantic_train[\"cluster\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_semantic_train['cluster'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_rows = len(df_queries_train)\n",
    "random_indices = np.random.choice(n_rows, size=int(0.15 * n_rows), replace=False)\n",
    "df_queries_train.loc[random_indices, 'answer_start'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(13139)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_queries_train['answer_start'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_semantic_train = X_semantic_train[:4000]\n",
    "df_semantic_train = df_semantic_train.iloc[:4000]\n",
    "\n",
    "df_queries_train = df_queries_train[df_queries_train[\"context_id\"].isin(df_semantic_train[\"context_id\"].unique())].reset_index(drop=True)\n",
    "\n",
    "labels_train = df_semantic_train[\"cluster\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 38692/87599 [1:39:50<2:06:29,  6.44it/s]"
     ]
    }
   ],
   "source": [
    "# Benchmark\n",
    "top_ks = [3, 5, 12, 25]\n",
    "top_n_clusters = [5, 10, 20, 35]\n",
    "\n",
    "# top_ks = [5, 10, 20]\n",
    "# top_n_clusters = [5, 10, 20]\n",
    "\n",
    "results_centroid = []\n",
    "results_full = []\n",
    "for top_k in top_ks:\n",
    "    # for top_n_cluster in top_n_clusters:\n",
    "    #     print(f\"Evaluating: Top-{top_k} chunks in Top-{top_n_cluster} clusters\")\n",
    "        \n",
    "    #     start_centroid = time.time()\n",
    "    #     centroid_metrics = evaluate_top_k_accuracy(df_queries_train, X_semantic_train, df_semantic_train, labels_train, top_n_clusters=top_n_cluster, top_k_total=top_k)\n",
    "    #     end_centroid = time.time()\n",
    "        \n",
    "    #     results_centroid.append({\n",
    "    #         \"top_k\": top_k,\n",
    "    #         \"top_n_clusters\": top_n_cluster,\n",
    "    #         \"centroid_metrics\": centroid_metrics,\n",
    "    #         \"centroid_time\": end_centroid - start_centroid\n",
    "    #     })\n",
    "        \n",
    "    #     results_df_centroid = pd.DataFrame(results_centroid)\n",
    "    #     results_df_centroid.to_excel(\"../data/results/hyperparameter_tuning_centroid_vs_full/centroid_results_kmeans500_v2_l2.xlsx\")\n",
    "        \n",
    "    start_full = time.time()\n",
    "    full_metrics = evaluate_top_k_accuracy_full(df_queries_train, X_semantic_train, df_semantic_train, top_k_chunks=top_k)\n",
    "    end_full = time.time()\n",
    "    results_full.append({\n",
    "        \"top_k\": top_k,\n",
    "        \"full_metrics\": full_metrics,\n",
    "        \"full_time\": end_full - start_full\n",
    "    })\n",
    "    results_df_full = pd.DataFrame(results_full)\n",
    "    results_df_full.to_excel(\"../data/results/hyperparameter_tuning_centroid_vs_full/full_results_kmeans500_v2_l2_corrected.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(labels_train)) / 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047619047619047616"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4000 / 84000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87599/87599 [3:28:17<00:00,  7.01it/s]   \n"
     ]
    }
   ],
   "source": [
    "start_full = time.time()\n",
    "full_metrics = evaluate_top_k_accuracy_full(df_queries_train, X_semantic_train, df_semantic_train, top_k_chunks=25)\n",
    "end_full = time.time()\n",
    "results_full.append({\n",
    "    \"top_k\": 25,\n",
    "    \"full_metrics\": full_metrics,\n",
    "    \"full_time\": end_full - start_full\n",
    "})\n",
    "results_df_full = pd.DataFrame(results_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_k</th>\n",
       "      <th>full_metrics</th>\n",
       "      <th>full_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>{'doc_accuracy': 0.8036735579173279, 'chunk_ac...</td>\n",
       "      <td>10972.379970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>{'doc_accuracy': 0.8522357561159374, 'chunk_ac...</td>\n",
       "      <td>10506.523075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>{'doc_accuracy': 0.9135035788079773, 'chunk_ac...</td>\n",
       "      <td>11872.974770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>{'doc_accuracy': 0.9460039498167787, 'chunk_ac...</td>\n",
       "      <td>12497.922858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   top_k                                       full_metrics     full_time\n",
       "0      3  {'doc_accuracy': 0.8036735579173279, 'chunk_ac...  10972.379970\n",
       "1      5  {'doc_accuracy': 0.8522357561159374, 'chunk_ac...  10506.523075\n",
       "2     12  {'doc_accuracy': 0.9135035788079773, 'chunk_ac...  11872.974770\n",
       "3     25  {'doc_accuracy': 0.9460039498167787, 'chunk_ac...  12497.922858"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_full.to_excel(\"../data/results/hyperparameter_tuning_centroid_vs_full/full_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate retrieval with MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_semantic_train = np.load(\"./data/tensors/squad_train_v2_semantic_chunking_l2.npy\")\n",
    "df_semantic_train = pd.read_excel(\"./data/prepared/squad_train_v2_semantic_chunking.xlsx\")\n",
    "df_queries_train = pd.read_excel(\"./data/prepared/squad_train_v2_queries.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Futtatás ---\n",
    "results_df = minibatchkmeans_retrieval_evaluation(\n",
    "    chunk_embeddings=X_semantic_train,\n",
    "    df_chunks=df_semantic_train,\n",
    "    df_queries=df_queries_train,\n",
    "    n_clusters=160,\n",
    "    batch_size=1000,\n",
    "    top_k_total=5,\n",
    "    init_fraction=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plotolás: Pontosság ---\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(results_df[\"batch\"], results_df[\"doc_accuracy\"], label=\"Doc Accuracy\", marker='o')\n",
    "plt.plot(results_df[\"batch\"], results_df[\"chunk_accuracy\"], label=\"Chunk Accuracy\", marker='s')\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Retrieval pontosság batchenként (Online KMeans)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- Plotolás: Futásidők ---\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(results_df[\"batch\"], results_df[\"init_time\"], label=\"Init time\", marker='o')\n",
    "plt.plot(results_df[\"batch\"], results_df[\"update_time\"], label=\"Update time\", marker='s')\n",
    "plt.plot(results_df[\"batch\"], results_df[\"retrieval_time\"], label=\"Retrieval time\", marker='^')\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Time (s)\")\n",
    "plt.title(\"Futásidők batchenként (Online KMeans)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate retrieval with online clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_semantic_train = np.load(\"../data/tensors/squad_train_v2_semantic_chunking_l2.npy\")\n",
    "df_semantic_train = pd.read_excel(\"../data/prepared/squad_train_v2_semantic_chunking.xlsx\")\n",
    "df_queries_train = pd.read_excel(\"../data/prepared/squad_train_v2_queries.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Using 50% of data (42003 samples) for initialization\n",
      "✅ Initialization done in 65.6504 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_queries_seen: 48817, seen_df_chunks: 44003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48817/48817 [17:23<00:00, 46.79it/s]\n",
      "  5%|▍         | 1/22 [17:24<6:05:30, 1044.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1] Seen chunks: 44003, Doc acc: 0.7526, Chunk acc: 0.6238, Clusters: 524\n",
      "df_queries_seen: 50578, seen_df_chunks: 46003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50578/50578 [19:28<00:00, 43.27it/s]\n",
      "  9%|▉         | 2/22 [36:54<6:12:44, 1118.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 2] Seen chunks: 46003, Doc acc: 0.7504, Chunk acc: 0.6206, Clusters: 524\n",
      "df_queries_seen: 52477, seen_df_chunks: 48003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52477/52477 [20:12<00:00, 43.27it/s]\n",
      " 14%|█▎        | 3/22 [57:08<6:07:56, 1161.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 3] Seen chunks: 48003, Doc acc: 0.7481, Chunk acc: 0.6187, Clusters: 526\n",
      "df_queries_seen: 54231, seen_df_chunks: 50003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54231/54231 [22:14<00:00, 40.64it/s]\n",
      " 18%|█▊        | 4/22 [1:19:23<6:09:09, 1230.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 4] Seen chunks: 50003, Doc acc: 0.7456, Chunk acc: 0.6149, Clusters: 544\n",
      "df_queries_seen: 56119, seen_df_chunks: 52003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56119/56119 [22:43<00:00, 41.15it/s]\n",
      " 23%|██▎       | 5/22 [1:42:08<6:02:22, 1278.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 5] Seen chunks: 52003, Doc acc: 0.7438, Chunk acc: 0.6129, Clusters: 544\n",
      "df_queries_seen: 58097, seen_df_chunks: 54003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58097/58097 [23:27<00:00, 41.27it/s]\n",
      " 27%|██▋       | 6/22 [2:05:37<5:52:51, 1323.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 6] Seen chunks: 54003, Doc acc: 0.7416, Chunk acc: 0.6102, Clusters: 544\n",
      "df_queries_seen: 59930, seen_df_chunks: 56003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59930/59930 [25:00<00:00, 39.94it/s]\n",
      " 32%|███▏      | 7/22 [2:30:39<5:45:22, 1381.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 7] Seen chunks: 56003, Doc acc: 0.7393, Chunk acc: 0.6087, Clusters: 544\n",
      "df_queries_seen: 61832, seen_df_chunks: 58003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61832/61832 [25:24<00:00, 40.56it/s]\n",
      " 36%|███▋      | 8/22 [2:56:05<5:33:05, 1427.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 8] Seen chunks: 58003, Doc acc: 0.7369, Chunk acc: 0.6063, Clusters: 544\n",
      "df_queries_seen: 63816, seen_df_chunks: 60003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63816/63816 [26:15<00:00, 40.51it/s]\n",
      " 41%|████      | 9/22 [3:22:22<5:19:24, 1474.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 9] Seen chunks: 60003, Doc acc: 0.7358, Chunk acc: 0.6046, Clusters: 550\n",
      "df_queries_seen: 65742, seen_df_chunks: 62003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65742/65742 [28:18<00:00, 38.70it/s]\n",
      " 45%|████▌     | 10/22 [3:50:42<5:08:48, 1544.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 10] Seen chunks: 62003, Doc acc: 0.7341, Chunk acc: 0.6039, Clusters: 550\n",
      "df_queries_seen: 67503, seen_df_chunks: 64003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67503/67503 [27:48<00:00, 40.46it/s]\n",
      " 50%|█████     | 11/22 [4:18:32<4:50:08, 1582.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 11] Seen chunks: 64003, Doc acc: 0.7335, Chunk acc: 0.6031, Clusters: 551\n",
      "df_queries_seen: 69330, seen_df_chunks: 66003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69330/69330 [28:42<00:00, 40.24it/s]\n",
      " 55%|█████▍    | 12/22 [4:47:17<4:30:57, 1625.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 12] Seen chunks: 66003, Doc acc: 0.7310, Chunk acc: 0.6008, Clusters: 551\n",
      "df_queries_seen: 71487, seen_df_chunks: 68003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71487/71487 [29:55<00:00, 39.82it/s]\n",
      " 59%|█████▉    | 13/22 [5:17:14<4:11:39, 1677.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 13] Seen chunks: 68003, Doc acc: 0.7297, Chunk acc: 0.5994, Clusters: 551\n",
      "df_queries_seen: 73342, seen_df_chunks: 70003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73342/73342 [31:08<00:00, 39.25it/s]\n",
      " 64%|██████▎   | 14/22 [5:48:24<3:51:26, 1735.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 14] Seen chunks: 70003, Doc acc: 0.7287, Chunk acc: 0.5980, Clusters: 552\n",
      "df_queries_seen: 75361, seen_df_chunks: 72003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75361/75361 [32:31<00:00, 38.62it/s]\n",
      " 68%|██████▊   | 15/22 [6:20:57<3:30:09, 1801.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 15] Seen chunks: 72003, Doc acc: 0.7256, Chunk acc: 0.5957, Clusters: 552\n",
      "df_queries_seen: 77458, seen_df_chunks: 74003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77458/77458 [33:13<00:00, 38.85it/s]\n",
      " 73%|███████▎  | 16/22 [6:54:13<3:05:58, 1859.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 16] Seen chunks: 74003, Doc acc: 0.7246, Chunk acc: 0.5954, Clusters: 554\n",
      "df_queries_seen: 79607, seen_df_chunks: 76003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79607/79607 [34:00<00:00, 39.01it/s]\n",
      " 77%|███████▋  | 17/22 [7:28:15<2:39:33, 1914.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 17] Seen chunks: 76003, Doc acc: 0.7247, Chunk acc: 0.5958, Clusters: 554\n",
      "df_queries_seen: 81585, seen_df_chunks: 78003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81585/81585 [36:48<00:00, 36.94it/s]\n",
      " 82%|████████▏ | 18/22 [8:05:06<2:13:34, 2003.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 18] Seen chunks: 78003, Doc acc: 0.7230, Chunk acc: 0.5942, Clusters: 554\n",
      "df_queries_seen: 83407, seen_df_chunks: 80003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83407/83407 [36:54<00:00, 37.66it/s]\n",
      " 86%|████████▋ | 19/22 [8:42:02<1:43:22, 2067.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 19] Seen chunks: 80003, Doc acc: 0.7227, Chunk acc: 0.5939, Clusters: 555\n",
      "df_queries_seen: 85432, seen_df_chunks: 82003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85432/85432 [37:16<00:00, 38.20it/s]\n",
      " 91%|█████████ | 20/22 [9:19:21<1:10:37, 2118.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 20] Seen chunks: 82003, Doc acc: 0.7207, Chunk acc: 0.5916, Clusters: 555\n",
      "df_queries_seen: 87594, seen_df_chunks: 84003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87594/87594 [38:46<00:00, 37.65it/s]\n",
      " 95%|█████████▌| 21/22 [9:58:09<36:21, 2181.84s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 21] Seen chunks: 84003, Doc acc: 0.7193, Chunk acc: 0.5901, Clusters: 555\n",
      "df_queries_seen: 87599, seen_df_chunks: 84007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87599/87599 [39:01<00:00, 37.41it/s]\n",
      "100%|██████████| 22/22 [10:37:13<00:00, 1737.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 22] Seen chunks: 84007, Doc acc: 0.7193, Chunk acc: 0.5901, Clusters: 555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_df = online_kmeans_retrieval_evaluation(\n",
    "    chunk_embeddings=X_semantic_train,\n",
    "    df_chunks=df_semantic_train,\n",
    "    df_queries=df_queries_train,\n",
    "    n_clusters=500,\n",
    "    max_clusters=2000,\n",
    "    batch_size=2000,\n",
    "    top_k_total=5,\n",
    "    metric=\"cosine\",\n",
    "    init_fraction=0.5,\n",
    "    merge_threshold=0.08,    \n",
    "    decay=1.0,\n",
    "    new_cluster_threshold=0.8\n",
    ")\n",
    "\n",
    "results_df.to_excel(\"../data/results/onlinekmeans_v2.xlsx\") # cluster500rol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "szakdoga",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
